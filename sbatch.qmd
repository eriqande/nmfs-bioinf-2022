# Submitting jobs with `sbatch` {#sbatch}

- Up till now we have allocated ourselves two cores for
_interactive_ use.

- This is what you would do if you were going to be doing computationally
intensive things directly while hacking on the command line....
- ...or if you were going to start an R session and interactively work
on some big data on it.
- etc.

Running an interactive shell on a compute node is also a great way
to test your scripts.

However, once your scripts are tested, for most of your heavy
computation, you will want to submit jobs as non-interactive _batch_ jobs
using SLURM's `sbatch` function.  

## The `sbatch` function and its options

If you do `man sbatch` you will see an insanely large number of options
and all sorts of complicated stuff.  

You can get by with a fairly minimal set of options for almost everything
you need to do.  They are:

- `--cpus-per-task=<n>`: the number of cores to use for the job.  The syntax has you
using it like this `--cpus-per-task=2`
    - On Sedna, the default is 1.
- `--mem=<size[units]`: How much total memory for the job. Example: `--mem=4G`
    - On Sedna, the default is about 4.7 Gb for each requested core.
- `--time=[D-]HH:MM:SS`: How much time are you requesting?  You don't have to specify days,
    so you could say, `--time=1-12:00:00` for one day and twelve hours, or you could
    say `--time=36:00:00`  for 36 hours.
    - On Sedna, the default is 8 hours. 
- `--output=<filename pattern>`: Where should anything on `stdout` that is not otherwise redirected be written to?
- `--error=<filename pattern>`: Where should anything on `stderr` that is not otherwise redirected be written to?

On top of the options,  `sbatch` takes a single required argument, which must be the
path to a shell script (we know about those!) that the job will run.

::: {.callout-warning}

## Fun fact:

If you pass any arguments after the name of the shell script that you want
`sbatch` to execute, those are interpreted as arguments to the shell script
itself.

:::

## What an invocation of `sbatch` could look like

So, if we wanted to schedule a script called `MyScript.sh` to run with 4 cores
and memory of 80Gb, with an allowance of 16 hours, and we wanted to tell
SLURM where to capture any otherwise un-redirected `stdout` and `stderr`, we
would type something like this:
```{.sh filename="Don't bother copying or pasting this."}
sbatch --cpus-per-task=4 --mem=80G --time=16:00:00 --output=myscript_stdout --error myscript_error MyScript.sh
```

Some points about that:

- Typing all of that is a huge hassle.
- Most of the options will be specific to the actual job in `MyScript.sh`

So...`sbatch` allows you to store the options in your shell script on lines
after the shebang line that are preceded by `#SBATCH`.

Let's look at an example, in the file `scripts/bwa_index.sh`
```{.sh filename="Contents of the file scripts/bwa_index.sh"}
`r paste(readLines("playground/scripts/bwa_index.sh"), collapse="\n")`
```

::: {.callout-warning}

### What's that %j in the output and error options?

In the above script, you will see

```{.sh}
#SBATCH --output=bwa_index-%j.out
#SBATCH --error=bwa_index-%j.err
```
In this context, the `%j` gets replace by `sbatch` with the
SLURM `JOBID`.

:::


## Let us submit the `bwa_index.sh` job to SLURM

Since all of the `sbatch` options are imbedded within the
shell script, all that we need to do, now, is:
```{.sh filename="Paste this into your shell"}
sbatch scripts/bwa_index.sh resources/genome.fasta
```

The first argument is the script `scripts/bwa_index.sh` and the
second, `resources/genome.fasta`, is the path to the genome that
we want to index with `bwa`.

When this command executes, it returns the SLURM `JOBID`.  Make a note of it.

Once you have launched the job, try using `myjobs` and `alljobs` to see your job running
in the queue, and also everyone else's. (You don't have much time, because it doesn't take very long).

::: {.callout-caution  collapse=true}

## Hey! That job ran in the current working directory

Note that our script ran `bwa index` by passing it the path of a
reference genome specified as a _relative path_: the path was relative
to our current working directory.

One of the wonderful features of SLURM is that, when `sbatch` runs your
script, it does so from the current working directory of the shell in which
you ran `sbatch`.  

(I mention this because the first cluster I used was set up differently,
and you had to explicitly tell it to run from the current working directory---which
was the source of endless gnashing of teeth)
:::

Once that job is done, use `ls -lrt resources` to see all the files that
were newly created by the `bwa-index.sh` script.

## How many resources did that job use? --- `seff`

When you first start doing bioinformatics, you will not be very familiar
with how long each job will run, or how much memory it will need.

That takes some time, but one helpful utility, `seff`, will tell you the
effective usage of the allocated resources by any _completed_ job.

It's simple to use:
```{.sh filename="Here is the sytnax"}
seff slurm-jobid
```

::: {.callout-tip}

## Self-study

Try that command, `seff slurm-jobid`, replacing `slurm-jobid` with the actual SLURM `JOBID` of the
job that you just ran.

:::


::: {.callout-warning collapse=true}

## More tips on learning about past job resource use

You can also use the `sacct` command.  Check it out with `man sacct`.

You can get information much like `seff` for your recent jobs with:
```{.sh filename="An example use of sacct"}

sacct  --format JobID,JobName,User,Group,State,Cluster,AllocCPUS,REQMEM,TotalCPU,Elapsed,MaxRSS,ExitCode,NNodes,NTasks -u $(whoami)

```

:::


## A simple job with default sbatch settings

We jumped right into talking about all the most useful options
for `sbatch`.

However, on Sedna (and, indeed, on most clusters), SLURM defines reasonable
defaults for an `sbatch` job.  

It even sends the `output` and `error` to reasonably named files, as we
shall see.

The following lists the contents of a script called `simple-15.sh`
that doesn't do much:

1. It writes out the SLURM_JOB_ID to `stdout`
2. It writes a message to `stderr`
3. Then it just sits there for 15 minutes.

```{.sh filename="Contents of scripts/simple-15.sh"}
`r paste(readLines("playground/scripts/simple-15.sh"), collapse = "\n")`
```

Now we will submit that script to run as a SLURM job with:
```{.sh filename="Paste this into your shell"}
sbatch scripts/simple-15.sh
```


## Oh no!  I need to stop my job(s): `scancel`


## What happens if we exceed our resources?


::: {.callout-warning }

## Memory gets allocated with cores or via `--mem`

It is quite clear that the `--mem` option to `sbatch` is
intended to increase the memory allocated to the job; however
adding cores with `--cpus-per-task` also increases the memory
available.

On Sedna, your job gets roughly 4700 Mb (4.7 Gb) of RAM for each
_core_ that it is allocated on one of the standard compute nodes.

Note, however, that if the programs running in your job are not
multithreaded, then you might not be able to use all those cores.
In which case, it might be better to specify additional memory allocation with
`--mem`, and leave the other cores to other users.

:::