# Welcome! {.unnumbered}

Welcome to the website for the National Marine Fisheries Service
Linux, Slurm, and Bioinformatics training to be held virtually
over three days:

* Day 1: Monday, October 17, 2022. 10 AM - 12 PM PDT
* Day 2: Tuesday, October 18, 2022. 10 AM - 12:30 PM PDT
* Day 3: Wednesday, October 19, 2022. 10 AM - 12 PM PDT


## Prerequisites

This course will be using the SEDNA high-performance computing
cluster located at the Northwest Fisheries Science Center. This cluster
(and, hence, this course)
is only available to NMFS employees and affiliates. If you are a NMFS
employee and you are interested in this course, please see 
[here](https://docs.google.com/document/d/1nn0T0OWEsQCBoCdaH6DSY69lQSbK3XnPlseyyQuU2Lc/edit#heading=h.qpx57rvxr0sj) for information about how to
get an account on the cluster. 

This course is intended for people who have already had some exposure
to Unix or Linux.  You should be reasonably comfortable navigating around 
the Unix filesystem using the command line.
For a refresher, please read [this chapter from my
online bioinformatics book](https://eriqande.github.io/eca-bioinf-handbook/essential-unixlinux-terminal-knowledge.html).


## Proposed Course Topics

* Day 1:
    - Introduction to the SEDNA cluster (15 minutes Krista and Giles)
        - Cluster infrastructure and configuration.
        - Scientific software and the installation requests
    - Shell Programming (40 Minutes)
        - Shell variables (setting and extracting values)
        - Exit status, and chaining commands with `&&`
        - Redirection of stdout and stderr, and pipes
        - Grouping commands with `(...)`
        - Capturing output into variables `$(...)`, and the need to use
        `eval` if you want to properly evaluate some constructs within them.
        - Looping with `for; do ...; done`
        - `bash` functions
        - Unix shell scripts (refresher on making things executable)
        - `basename` and `dirname`.
    - Processing text files with `awk` (35 minutes)
    - Putting these together with some examples. (20 minutes)
* Day 2:
    - Computing clusters and Slurm (three 33 minute sessions,
    punctuated by two 10 minute breaks).  We will be exploring the
    use of all of these with some bioinformatic tasks.  Like indexing
    a genome. Mapping some reads, etc.
        - Homework: read from the beginning of the chapter
        to the end of section 8.2   [here](https://eriqande.github.io/eca-bioinf-handbook/chap-HPCC.html)
        - Learning about the cluster and your jobs: `sinfo` and `squeue`
        - Write a convenience bash function or two: `myjobs` and `alljobs`
        - Getting an interactive session on a compute node: `srun`
        - Environment modules on SEDNA: `module`
        - Submitting jobs to the queue: `sbatch`
        - Job arrays.
        - A useful script for orchestrating job arrays from a spreadsheet: `line-assign.sh`.  This will build off of
          what we learned the day before.
        - `scancel`: Help!  I need to kill that job (or all the jobs) that I just started!
        - `seff`: get information on resource use of a job I already ran.

* Day 3:
    - An introduction to Snakemake
        - Will somewhat follow [these slides](https://eriqande.github.io/con-gen-2022/slides/snake-slides.html#/section)
        - BUT, it will be modified to show use of SEDNA's environment modules
        and also to show use of a profile for dispatching jobs to Slurm from
        Snakemake.


